{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HubSpot ML Framework - Complete Demo\n",
    "## Training with MLflow + Serving with FastAPI\n",
    "\n",
    "**What this notebook demonstrates:**\n",
    "1. Training a customer conversion model\n",
    "2. Tracking experiments with MLflow\n",
    "3. Testing the FastAPI prediction service\n",
    "4. End-to-end ML workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Environment Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç Environment Check\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# If in notebooks/ directory, move to project root\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "    print(f\"‚úì Changed to project root: {os.getcwd()}\")\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = Path(os.getcwd()) / 'src'\n",
    "if src_path.exists():\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"‚úì Added to path: {src_path}\")\n",
    "\n",
    "# Verify directory structure\n",
    "print(f\"\\nüìÅ Directory Check:\")\n",
    "for folder in ['data', 'configs', 'artifacts', 'mlruns']:\n",
    "    exists = Path(folder).exists()\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"  {status} {folder}/ exists: {exists}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries\n",
    "from ml_framework.training import Trainer\n",
    "from ml_framework.utils import load_config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "\n",
    "# For API testing\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Configuration\n",
    "config = load_config('configs/config.yaml')\n",
    "\n",
    "print(\"üìã Configuration Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Experiment: {config.experiment.name}\")\n",
    "print(f\"Model: {config.model.type}\")\n",
    "print(f\"MLflow URI: {config.experiment.mlflow_tracking_uri}\")\n",
    "print(f\"Test size: {config.data.test_size}\")\n",
    "print(f\"Random seed: {config.reproducibility.seed}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Part 1: Model Training with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train Model\n",
    "print(\"üöÄ Starting Model Training with MLflow Tracking\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Run training (automatically logs to MLflow)\n",
    "results = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"  Accuracy:  {results['metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {results['metrics']['precision']:.4f}\")\n",
    "print(f\"  Recall:    {results['metrics']['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {results['metrics']['f1']:.4f}\")\n",
    "print(f\"\\nüíæ Model saved to: {results['model_path']}\")\n",
    "print(f\"üìù MLflow Run ID: {results['run_id']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¨ Explore MLflow Tracking\n",
    "\n",
    "**To view experiments:**\n",
    "1. Open a new terminal\n",
    "2. Run: `mlflow ui --backend-store-uri ./mlruns`\n",
    "3. Open browser: http://localhost:5000\n",
    "\n",
    "**What you'll see:**\n",
    "- All training runs\n",
    "- Metrics comparison charts\n",
    "- Hyperparameters\n",
    "- Saved artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: View MLflow Runs Programmatically\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(config.experiment.name)\n",
    "\n",
    "if experiment:\n",
    "    runs = client.search_runs(experiment.experiment_id)\n",
    "    \n",
    "    print(f\"üìä MLflow Experiment: {config.experiment.name}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total runs: {len(runs)}\\n\")\n",
    "    \n",
    "    for run in runs[:5]:  # Show last 5 runs\n",
    "        print(f\"Run ID: {run.info.run_id[:8]}...\")\n",
    "        print(f\"  Status: {run.info.status}\")\n",
    "        print(f\"  Start: {datetime.fromtimestamp(run.info.start_time / 1000)}\")\n",
    "        print(f\"  Metrics:\")\n",
    "        for key, value in run.data.metrics.items():\n",
    "            print(f\"    {key}: {value:.4f}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No experiment found. Run training first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Visualize Metrics Across Runs\n",
    "if experiment and len(runs) > 0:\n",
    "    # Extract metrics from all runs\n",
    "    metrics_data = []\n",
    "    for run in runs:\n",
    "        metrics_data.append({\n",
    "            'run_id': run.info.run_id[:8],\n",
    "            'accuracy': run.data.metrics.get('accuracy', 0),\n",
    "            'precision': run.data.metrics.get('precision', 0),\n",
    "            'recall': run.data.metrics.get('recall', 0),\n",
    "            'f1': run.data.metrics.get('f1', 0)\n",
    "        })\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    df_metrics.set_index('run_id')[['accuracy', 'precision', 'recall', 'f1']].plot(\n",
    "        kind='bar', ax=ax, width=0.8\n",
    "    )\n",
    "    ax.set_title('Model Performance Across Runs', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Run ID', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend(title='Metrics')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìà Metrics Summary:\")\n",
    "    print(df_metrics.describe())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No runs to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üöÄ Part 2: FastAPI Testing\n",
    "\n",
    "**Before running these cells:**\n",
    "1. Open a NEW terminal\n",
    "2. Run: `python run_api.py`\n",
    "3. Server starts on http://localhost:8000\n",
    "4. View docs: http://localhost:8000/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Check API Health\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/health\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        health_data = response.json()\n",
    "        print(\"‚úÖ API is healthy and ready for predictions!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Status: {health_data.get('status')}\")\n",
    "        print(f\"Model Loaded: {health_data.get('model_loaded')}\")\n",
    "        if 'model_version' in health_data:\n",
    "            print(f\"Model Version: {health_data.get('model_version')}\")\n",
    "        print(\"=\" * 60)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è API returned status code: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Cannot connect to API!\")\n",
    "    print(\"\\nüìù To start the API:\")\n",
    "    print(\"1. Open a new terminal\")\n",
    "    print(\"2. cd to project root\")\n",
    "    print(\"3. Run: python run_api.py\")\n",
    "    print(\"4. Then re-run this cell\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Single Company Prediction\n",
    "print(\"üéØ Testing Single Prediction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example company data\n",
    "company_data = {\n",
    "    \"id\": 123,\n",
    "    \"ALEXA_RANK\": 50000,\n",
    "    \"EMPLOYEE_RANGE\": \"26 to 50\",\n",
    "    \"INDUSTRY\": \"COMPUTER_SOFTWARE\",\n",
    "    \"total_actions\": 150,\n",
    "    \"total_users\": 5,\n",
    "    \"days_active\": 30,\n",
    "    \"activity_frequency\": 5.0\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict/single\",\n",
    "        json=company_data,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        \n",
    "        print(f\"Company ID: {result['company_id']}\")\n",
    "        print(\"\\nüìä Prediction Result:\")\n",
    "        \n",
    "        prediction_label = \"üü¢ CUSTOMER\" if result['prediction'] == 1 else \"üî¥ NON-CUSTOMER\"\n",
    "        print(f\"  {prediction_label}\")\n",
    "        print(f\"  Probability: {result['conversion_probability']:.2%}\")\n",
    "        print(f\"  Confidence: {result['confidence'].upper()}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, ax = plt.subplots(figsize=(8, 2))\n",
    "        prob = result['conversion_probability']\n",
    "        ax.barh(['Conversion Probability'], [prob], color='green' if prob > 0.5 else 'red')\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_xlabel('Probability', fontsize=12)\n",
    "        ax.set_title(f'Prediction: {prediction_label}', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå API not running! Start it with: python run_api.py\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Batch Predictions\n",
    "print(\"üì¶ Testing Batch Predictions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Multiple companies\n",
    "companies_batch = [\n",
    "    {\n",
    "        \"id\": 101,\n",
    "        \"ALEXA_RANK\": 10000,\n",
    "        \"EMPLOYEE_RANGE\": \"51 to 100\",\n",
    "        \"INDUSTRY\": \"COMPUTER_SOFTWARE\",\n",
    "        \"total_actions\": 300,\n",
    "        \"total_users\": 15,\n",
    "        \"days_active\": 45,\n",
    "        \"activity_frequency\": 6.7\n",
    "    },\n",
    "    {\n",
    "        \"id\": 102,\n",
    "        \"ALEXA_RANK\": 500000,\n",
    "        \"EMPLOYEE_RANGE\": \"1 to 10\",\n",
    "        \"INDUSTRY\": \"RETAIL\",\n",
    "        \"total_actions\": 10,\n",
    "        \"total_users\": 1,\n",
    "        \"days_active\": 5,\n",
    "        \"activity_frequency\": 2.0\n",
    "    },\n",
    "    {\n",
    "        \"id\": 103,\n",
    "        \"ALEXA_RANK\": 75000,\n",
    "        \"EMPLOYEE_RANGE\": \"26 to 50\",\n",
    "        \"INDUSTRY\": \"INTERNET\",\n",
    "        \"total_actions\": 180,\n",
    "        \"total_users\": 8,\n",
    "        \"days_active\": 35,\n",
    "        \"activity_frequency\": 5.1\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict/batch\",\n",
    "        json=companies_batch,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        \n",
    "        print(f\"Processed {len(results)} companies:\\n\")\n",
    "        \n",
    "        for result in results:\n",
    "            prediction_label = \"‚úÖ Customer\" if result['prediction'] == 1 else \"‚ùå Non-Customer\"\n",
    "            print(f\"Company {result['company_id']}: {prediction_label} ({result['conversion_probability']:.1%})\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Visualize batch results\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results['label'] = df_results['prediction'].apply(\n",
    "            lambda x: 'Customer' if x == 1 else 'Non-Customer'\n",
    "        )\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Probability distribution\n",
    "        colors = ['green' if p > 0.5 else 'red' for p in df_results['conversion_probability']]\n",
    "        ax1.bar(df_results['company_id'], df_results['conversion_probability'], color=colors)\n",
    "        ax1.axhline(y=0.5, color='black', linestyle='--', label='Decision Boundary')\n",
    "        ax1.set_xlabel('Company ID', fontsize=12)\n",
    "        ax1.set_ylabel('Conversion Probability', fontsize=12)\n",
    "        ax1.set_title('Batch Prediction Probabilities', fontsize=14, fontweight='bold')\n",
    "        ax1.legend()\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Prediction distribution\n",
    "        prediction_counts = df_results['label'].value_counts()\n",
    "        ax2.pie(prediction_counts, labels=prediction_counts.index, autopct='%1.1f%%',\n",
    "                colors=['green', 'red'], startangle=90)\n",
    "        ax2.set_title('Prediction Distribution', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå API not running! Start it with: python run_api.py\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Top Conversion Prospects\n",
    "print(\"üéØ Finding Top Conversion Prospects\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate sample companies\n",
    "np.random.seed(42)\n",
    "sample_companies = []\n",
    "\n",
    "industries = [\"COMPUTER_SOFTWARE\", \"INTERNET\", \"RETAIL\", \"MARKETING\"]\n",
    "employee_ranges = [\"1 to 10\", \"11 to 25\", \"26 to 50\", \"51 to 100\"]\n",
    "\n",
    "for i in range(10):\n",
    "    sample_companies.append({\n",
    "        \"id\": 1000 + i,\n",
    "        \"ALEXA_RANK\": np.random.randint(10000, 200000),\n",
    "        \"EMPLOYEE_RANGE\": np.random.choice(employee_ranges),\n",
    "        \"INDUSTRY\": np.random.choice(industries),\n",
    "        \"total_actions\": np.random.randint(50, 400),\n",
    "        \"total_users\": np.random.randint(2, 20),\n",
    "        \"days_active\": np.random.randint(10, 60),\n",
    "        \"activity_frequency\": np.random.uniform(2.0, 8.0)\n",
    "    })\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict/batch\",\n",
    "        json=sample_companies,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        \n",
    "        # Sort by probability\n",
    "        df_prospects = pd.DataFrame(results)\n",
    "        df_prospects = df_prospects.sort_values('conversion_probability', ascending=False)\n",
    "        \n",
    "        print(\"\\nüèÜ Top 5 Conversion Prospects:\\n\")\n",
    "        for idx, row in df_prospects.head(5).iterrows():\n",
    "            print(f\"#{df_prospects.index.get_loc(idx) + 1}. Company {row['company_id']}\")\n",
    "            print(f\"   Probability: {row['conversion_probability']:.1%}\")\n",
    "            print(f\"   Confidence: {row['confidence'].upper()}\")\n",
    "            print()\n",
    "        \n",
    "        # Visualize top prospects\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        top_10 = df_prospects.head(10)\n",
    "        colors = ['green' if x >= 0.7 else 'orange' if x >= 0.5 else 'red' \n",
    "                  for x in top_10['conversion_probability']]\n",
    "        \n",
    "        ax.barh(top_10['company_id'].astype(str), top_10['conversion_probability'], color=colors)\n",
    "        ax.set_xlabel('Conversion Probability', fontsize=12)\n",
    "        ax.set_ylabel('Company ID', fontsize=12)\n",
    "        ax.set_title('Top 10 Conversion Prospects', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.axvline(x=0.5, color='black', linestyle='--', label='50% Threshold')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå API not running!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö API Documentation & Testing\n",
    "\n",
    "**Interactive API Documentation:**\n",
    "- Swagger UI: http://localhost:8000/docs\n",
    "- ReDoc: http://localhost:8000/redoc\n",
    "\n",
    "**Available Endpoints:**\n",
    "- `GET /health` - Check API health\n",
    "- `POST /predict/single` - Single prediction\n",
    "- `POST /predict/batch` - Batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: View API Info\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/docs\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ API Documentation Available\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nüìñ Interactive Documentation:\")\n",
    "        print(f\"   Swagger UI: {API_URL}/docs\")\n",
    "        print(f\"   ReDoc:      {API_URL}/redoc\")\n",
    "        print(\"\\nüîå Available Endpoints:\")\n",
    "        print(f\"   GET  {API_URL}/health\")\n",
    "        print(f\"   POST {API_URL}/predict/single\")\n",
    "        print(f\"   POST {API_URL}/predict/batch\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nüí° Tip: Open the Swagger UI in your browser to test interactively!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Unexpected status code: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå API not running\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. **‚úÖ Trained a customer conversion model**\n",
    "   - Random Forest classifier\n",
    "   - Feature engineering from company and activity data\n",
    "   - Train/test split for evaluation\n",
    "\n",
    "2. **‚úÖ Tracked experiments with MLflow**\n",
    "   - Logged hyperparameters\n",
    "   - Logged metrics (accuracy, precision, recall, F1)\n",
    "   - Saved model artifacts\n",
    "   - Compared runs visually\n",
    "\n",
    "3. **‚úÖ Served predictions via FastAPI**\n",
    "   - Health check endpoint\n",
    "   - Single prediction endpoint\n",
    "   - Batch prediction endpoint\n",
    "   - Interactive API documentation\n",
    "\n",
    "### Complete Workflow:\n",
    "\n",
    "```\n",
    "Data (CSV) ‚Üí Preprocessing ‚Üí Training ‚Üí MLflow Tracking\n",
    "                                ‚Üì\n",
    "                          Save Artifacts\n",
    "                                ‚Üì\n",
    "                          FastAPI Loads Model\n",
    "                                ‚Üì\n",
    "                          REST API Predictions\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- üîÑ Experiment with different models (XGBoost, LightGBM)\n",
    "- üéØ Tune hyperparameters\n",
    "- üìä Add more features\n",
    "- üöÄ Deploy to production\n",
    "- üìà Add monitoring and logging\n",
    "\n",
    "---\n",
    "**üéâ Congratulations! You've built a complete ML system with MLflow tracking and FastAPI serving!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
