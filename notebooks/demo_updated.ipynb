{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d81fc7a-04be-4ce9-9b37-7e65d725acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\Jahnavi Gajula\\Hubspot_Assesment\\ml-framework-package\\notebooks\n",
      "Files in current directory: ['.ipynb_checkpoints', 'artifacts', 'demo.ipynb', 'demo_updated.ipynb']\n",
      "Data folder exists: False\n"
     ]
    }
   ],
   "source": [
    "# Cell [1]: Check Environment\n",
    "import os\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Files in current directory: {os.listdir('.')}\")\n",
    "print(f\"Data folder exists: {os.path.exists('data')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db34b82-c666-4e93-be1c-a47bbfca66c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Changed to: C:\\Users\\Jahnavi Gajula\\Hubspot_Assesment\\ml-framework-package\n",
      "‚úì Added to path: C:\\Users\\Jahnavi Gajula\\Hubspot_Assesment\\ml-framework-package\\src\n",
      "‚úì Data folder exists: True\n"
     ]
    }
   ],
   "source": [
    "# Cell [2]: Setup Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If you're in notebooks/, change directory to parent\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "    print(f\"‚úì Changed to: {os.getcwd()}\")\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "print(f\"‚úì Added to path: {os.path.join(os.getcwd(), 'src')}\")\n",
    "print(f\"‚úì Data folder exists: {os.path.exists('data')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec3a880-0d44-49f6-ab8c-64382b6b41d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "============================================================\n",
      "Experiment: customer_conversion_baseline\n",
      "Model: logistic_regression\n",
      "MLflow URI: ./mlruns\n",
      "Test size: 0.2\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell [3]: Import and Load Config\n",
    "from ml_framework.training import Trainer\n",
    "from ml_framework.utils import load_config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For API testing\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Load configuration\n",
    "config = load_config('configs/config.yaml')\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Experiment: {config.experiment.name}\")\n",
    "print(f\"Model: {config.model.type}\")\n",
    "print(f\"MLflow URI: {config.experiment.mlflow_tracking_uri}\")\n",
    "print(f\"Test size: {config.data.test_size}\")\n",
    "print(f\"Random seed: {config.reproducibility.seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e61a52-39d6-4b25-abb7-54509bff7957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with MLflow tracking...\n",
      "============================================================\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Experiment 'customer_conversion_baseline' initialized\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Set random seed: 42\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - MLflow tracking URI: ./mlruns\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - MLflow experiment: customer_conversion_baseline\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Artifact directory: artifacts\\customer_conversion_baseline_20251109_152156\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Trainer initialized for experiment: customer_conversion_baseline\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - ============================================================\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Starting experiment: customer_conversion_baseline\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - ============================================================\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Loading data from configured paths...\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "customers validation WARNINGS:\n",
      "  ‚ö†Ô∏è  Found 4 customers (2.0%) with MRR ‚â§ 0 (pipeline will clean these)\n",
      "\n",
      "noncustomers validation WARNINGS:\n",
      "  ‚ö†Ô∏è  Soft uniqueness check failed for key ('id',): 3 duplicates found (acceptable but flagged)\n",
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è  DUPLICATES FOUND: noncustomers\n",
      "======================================================================\n",
      "Found 6 duplicate rows for key=['id']\n",
      "Unique IDs affected: 3\n",
      "Strategy 'most_complete' will be applied.\n",
      "\n",
      "\n",
      "Sample duplicate groups:\n",
      "      id  _duplicate_group\n",
      "447  278                 0\n",
      "446  278                 0\n",
      "923  279                 1\n",
      "922  279                 1\n",
      "443  280                 2\n",
      "444  280                 2\n",
      "\n",
      "üóëÔ∏è  Removed 3 duplicate rows\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è  Found 4 customers with MRR <= 0 (2.00%)\n",
      "======================================================================\n",
      "Business rule: Customers (is_customer = 1) must have MRR > 0\n",
      "\n",
      "Sample invalid rows:\n",
      "     id     MRR\n",
      "2   118  -61.15\n",
      "5   141 -403.20\n",
      "6   197 -260.00\n",
      "19    3 -555.00\n",
      "\n",
      "üóëÔ∏è  Removed 4 invalid customers\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Loaded data: 5196 samples, 36 features\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - n_samples: 5196\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - n_features: 36\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - n_customers: 196\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - n_noncustomers: 5000\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Splitting data...\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Train: 4156 samples, Test: 1040 samples\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - train_size: 4156\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - test_size: 1040\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Preprocessing data (fit=True)...\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Configured: missing_strategy=auto, industry_min_freq=5, scaling=standard\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Preprocessed shape: (4156, 84)\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Preprocessing data (fit=False)...\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Preprocessed shape: (1040, 84)\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Training logistic_regression model...\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - model_C: 1.0\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - model_penalty: l2\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - model_solver: lbfgs\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - model_max_iter: 1000\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Parameter - model_class_weight: balanced\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Model training complete\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Performing cross-validation...\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - CV ROC-AUC: 0.9617 (+/- 0.0156)\n",
      "2025-11-09 15:21:56 - experiment.customer_conversion_baseline - INFO - Evaluating model...\n",
      "\n",
      "==================================================\n",
      "MODEL PERFORMANCE METRICS\n",
      "==================================================\n",
      "ACCURACY...................... 0.9442\n",
      "PRECISION..................... 0.3827\n",
      "RECALL........................ 0.7949\n",
      "F1............................ 0.5167\n",
      "ROC_AUC....................... 0.9510\n",
      "AVERAGE_PRECISION............. 0.6449\n",
      "==================================================\n",
      "\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Metric - accuracy: 0.9442\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Metric - precision: 0.3827\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Metric - recall: 0.7949\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Metric - f1: 0.5167\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Metric - roc_auc: 0.9510\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Metric - average_precision: 0.6449\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saving artifacts...\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved model to artifacts\\customer_conversion_baseline_20251109_152156\\models\\model.joblib\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved feature engineer to artifacts\\customer_conversion_baseline_20251109_152156\\models\\feature_engineer.joblib\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved all preprocessing transformers\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved metrics to artifacts\\customer_conversion_baseline_20251109_152156\\metrics\\metrics.json\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved feature importance to artifacts\\customer_conversion_baseline_20251109_152156\\metrics\\feature_importance.csv\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved training data to artifacts\\customer_conversion_baseline_20251109_152156\\data\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO -   - train_data.csv: (4156, 85)\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO -   - test_data.csv: (1040, 85)\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - Saved config to artifacts\\customer_conversion_baseline_20251109_152156\\config.yaml\n",
      "2025-11-09 15:21:59 - experiment.customer_conversion_baseline - INFO - All artifacts saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jahnavi Gajula\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-09 15:22:04 - experiment.customer_conversion_baseline - INFO - MLflow Run ID: f707c95e271444bd9d266b2ec9068775\n",
      "2025-11-09 15:22:04 - experiment.customer_conversion_baseline - INFO - ============================================================\n",
      "2025-11-09 15:22:04 - experiment.customer_conversion_baseline - INFO - Experiment complete!\n",
      "2025-11-09 15:22:04 - experiment.customer_conversion_baseline - INFO - ============================================================\n",
      "\n",
      "============================================================\n",
      "‚úÖ TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Metrics:\n",
      "  accuracy: 0.9442\n",
      "  precision: 0.3827\n",
      "  recall: 0.7949\n",
      "  f1: 0.5167\n",
      "  roc_auc: 0.9510\n",
      "  average_precision: 0.6449\n",
      "\n",
      "Artifacts saved to: artifacts\\customer_conversion_baseline_20251109_152156\n",
      "\n",
      "üí° Check console output above for 'MLflow Run ID'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'customer_conversion_baseline_model' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'customer_conversion_baseline_model'.\n"
     ]
    }
   ],
   "source": [
    "# Cell [4]: Initialize and Train (WITH MLFLOW!)\n",
    "print(\"Starting training with MLflow tracking...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Run training (this will log to MLflow automatically)\n",
    "results = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMetrics:\")\n",
    "for metric, value in results['metrics'].items():\n",
    "    if value is not None:\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nArtifacts saved to: {results['artifact_dir']}\")\n",
    "print(\"\\nüí° Check console output above for 'MLflow Run ID'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8daaf862-3e31-4ee1-90f2-8892dc522e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 3 runs in experiment 'customer_conversion_baseline'\n",
      "============================================================\n",
      "\n",
      "üèÉ Latest Run:\n",
      "  Run ID: 5968fa55a74c4d6e98a36bc295eb9a1c\n",
      "  Start Time: 2025-11-09 21:20:04.002000+00:00\n",
      "  Status: FINISHED\n",
      "\n",
      "üìà Metrics:\n",
      "  roc_auc: 0.9510\n",
      "  accuracy: 0.9442\n",
      "  precision: 0.3827\n",
      "  recall: 0.7949\n",
      "  f1: 0.5167\n",
      "\n",
      "‚öôÔ∏è  Parameters:\n",
      "  lookback_days: 30\n",
      "  random_state: 42\n",
      "  model_type: logistic_regression\n",
      "  test_size: 0.2\n",
      "\n",
      "üìã All Runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "      <th>metrics.roc_auc</th>\n",
       "      <th>params.model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5968fa55a74c4d6e98a36bc295eb9a1c</td>\n",
       "      <td>2025-11-09 21:20:04.002000+00:00</td>\n",
       "      <td>0.944231</td>\n",
       "      <td>0.950998</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325667bbe0654d828428ac5082be7f1c</td>\n",
       "      <td>2025-11-09 18:35:20.136000+00:00</td>\n",
       "      <td>0.944231</td>\n",
       "      <td>0.950998</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ad6390915214234a4f87c3cc42568a9</td>\n",
       "      <td>2025-11-09 17:49:41.960000+00:00</td>\n",
       "      <td>0.944231</td>\n",
       "      <td>0.950998</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id                       start_time  \\\n",
       "0  5968fa55a74c4d6e98a36bc295eb9a1c 2025-11-09 21:20:04.002000+00:00   \n",
       "1  325667bbe0654d828428ac5082be7f1c 2025-11-09 18:35:20.136000+00:00   \n",
       "2  3ad6390915214234a4f87c3cc42568a9 2025-11-09 17:49:41.960000+00:00   \n",
       "\n",
       "   metrics.accuracy  metrics.roc_auc    params.model_type  \n",
       "0          0.944231         0.950998  logistic_regression  \n",
       "1          0.944231         0.950998  logistic_regression  \n",
       "2          0.944231         0.950998  logistic_regression  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell [5]: View MLflow Runs\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Set tracking URI\n",
    "mlflow.set_tracking_uri(config.experiment.mlflow_tracking_uri)\n",
    "\n",
    "# Search for runs\n",
    "runs = mlflow.search_runs(experiment_names=[config.experiment.name])\n",
    "\n",
    "print(f\"üìä Found {len(runs)} runs in experiment '{config.experiment.name}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(runs) > 0:\n",
    "    latest = runs.iloc[0]\n",
    "    print(f\"\\nüèÉ Latest Run:\")\n",
    "    print(f\"  Run ID: {latest['run_id']}\")\n",
    "    print(f\"  Start Time: {latest['start_time']}\")\n",
    "    print(f\"  Status: {latest['status']}\")\n",
    "    \n",
    "    print(f\"\\nüìà Metrics:\")\n",
    "    for col in runs.columns:\n",
    "        if col.startswith('metrics.'):\n",
    "            metric_name = col.replace('metrics.', '')\n",
    "            if pd.notna(latest[col]):\n",
    "                print(f\"  {metric_name}: {latest[col]:.4f}\")\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è  Parameters:\")\n",
    "    for col in runs.columns:\n",
    "        if col.startswith('params.'):\n",
    "            param_name = col.replace('params.', '')\n",
    "            if pd.notna(latest[col]):\n",
    "                print(f\"  {param_name}: {latest[col]}\")\n",
    "    \n",
    "    # Display runs dataframe\n",
    "    print(f\"\\nüìã All Runs:\")\n",
    "    display(runs[['run_id', 'start_time', 'metrics.accuracy', 'metrics.roc_auc', 'params.model_type']].head())\n",
    "else:\n",
    "    print(\"‚ùå No runs found! Train a model first (run Cell [4])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb389422-38d2-4f6b-9154-3a6c65ce2d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from MLflow...\n",
      "Run ID: 5968fa55a74c4d6e98a36bc295eb9a1c\n",
      "‚úÖ Model loaded successfully!\n",
      "Model type: LogisticRegression\n",
      "\n",
      "üìä Model expects 84 features\n"
     ]
    }
   ],
   "source": [
    "# Cell [6]: Load Model from MLflow\n",
    "if len(runs) > 0:\n",
    "    latest_run_id = runs.iloc[0]['run_id']\n",
    "    \n",
    "    print(f\"Loading model from MLflow...\")\n",
    "    print(f\"Run ID: {latest_run_id}\")\n",
    "    \n",
    "    # Load model\n",
    "    model_uri = f\"runs:/{latest_run_id}/model\"\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"Model type: {type(loaded_model).__name__}\")\n",
    "    \n",
    "    # Get feature names from artifacts\n",
    "    import joblib\n",
    "    from pathlib import Path\n",
    "    \n",
    "    artifact_dir = Path(results['artifact_dir'])\n",
    "    feature_engineer_path = artifact_dir / 'models' / 'feature_engineer.joblib'\n",
    "    \n",
    "    if feature_engineer_path.exists():\n",
    "        feature_engineer = joblib.load(feature_engineer_path)\n",
    "        print(f\"\\nüìä Model expects {len(feature_engineer.feature_names)} features\")\n",
    "else:\n",
    "    print(\"‚ùå No runs to load model from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d31caf8-49b7-4474-b380-9a4046ff2dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè• Testing FastAPI Health Check\n",
      "============================================================\n",
      "‚úÖ API is running!\n",
      "{\n",
      "  \"status\": \"healthy\",\n",
      "  \"service\": \"HubSpot Customer Conversion API\",\n",
      "  \"version\": \"1.0.0\"\n",
      "}\n",
      "\n",
      "üìä Health Check:\n",
      "‚ùå Error: Expecting value: line 1 column 1 (char 0)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell [8]: Test FastAPI - Health Check\n",
    "# ============================================================\n",
    "print(\"üè• Testing FastAPI Health Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "try:\n",
    "    # Test root endpoint\n",
    "    response = requests.get(f\"{API_BASE_URL}/\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ API is running!\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "    \n",
    "    # Test health endpoint\n",
    "    print(\"\\nüìä Health Check:\")\n",
    "    response = requests.get(f\"{API_BASE_URL}/health\", timeout=5)\n",
    "    health_data = response.json()\n",
    "    \n",
    "    print(f\"  Status: {health_data['status']}\")\n",
    "    print(f\"  Model Loaded: {health_data['model_loaded']}\")\n",
    "    print(f\"  Model Version: {health_data['model_version']}\")\n",
    "    \n",
    "    if health_data['status'] == 'healthy':\n",
    "        print(\"\\n‚úÖ API is healthy and ready for predictions!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  API is running but model not loaded\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Cannot connect to API!\")\n",
    "    print(\"\\nüí° To start the API, run in a new terminal:\")\n",
    "    print(\"   python run_api.py\")\n",
    "    print(\"\\n   Then rerun this cell.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8e9cbc-c2f7-494f-a429-3af618daf74d",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (334759546.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 35\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"  Prediction: {'üü¢ CUSTOMER' if result['prediction'] == 1 else 'üî¥ NON-CUSTOMER'}\")\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31m_IncompleteInputError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4fd2b-bde4-4593-82a0-5e16fd0f5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [7]: Compare Multiple Runs (Run this after training several times)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "runs = mlflow.search_runs(experiment_names=[config.experiment.name])\n",
    "\n",
    "if len(runs) > 1:\n",
    "    print(f\"Comparing {len(runs)} runs...\")\n",
    "    \n",
    "    # Sort by time\n",
    "    runs_sorted = runs.sort_values('start_time')\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].plot(range(len(runs_sorted)), runs_sorted['metrics.accuracy'], \n",
    "                 marker='o', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Run Number', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].set_title('Accuracy Across Runs', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROC AUC\n",
    "    axes[1].plot(range(len(runs_sorted)), runs_sorted['metrics.roc_auc'], \n",
    "                 marker='s', color='orange', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel('Run Number', fontsize=12)\n",
    "    axes[1].set_ylabel('ROC AUC', fontsize=12)\n",
    "    axes[1].set_title('ROC AUC Across Runs', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best run\n",
    "    print(f\"\\nüèÜ Best Run by ROC AUC:\")\n",
    "    best_idx = runs_sorted['metrics.roc_auc'].idxmax()\n",
    "    best_run = runs_sorted.loc[best_idx]\n",
    "    print(f\"  Run ID: {best_run['run_id']}\")\n",
    "    print(f\"  ROC AUC: {best_run['metrics.roc_auc']:.4f}\")\n",
    "    print(f\"  Accuracy: {best_run['metrics.accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {best_run['metrics.precision']:.4f}\")\n",
    "    print(f\"  Recall: {best_run['metrics.recall']:.4f}\")\n",
    "    \n",
    "elif len(runs) == 1:\n",
    "    print(f\"Only 1 run found. Train more models to compare!\")\n",
    "    print(f\"üí° Tip: Change hyperparameters in config.yaml and run Cell [4] again\")\n",
    "else:\n",
    "    print(\"No runs found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03535972-c709-408a-837f-c93617c1c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [8]: View MLflow Artifacts\n",
    "if len(runs) > 0:\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    latest_run_id = runs.iloc[0]['run_id']\n",
    "    \n",
    "    print(f\"üìÅ Artifacts for Run: {latest_run_id}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    artifacts = client.list_artifacts(latest_run_id)\n",
    "    \n",
    "    for artifact in artifacts:\n",
    "        print(f\"üì¶ {artifact.path}\")\n",
    "        if artifact.is_dir:\n",
    "            # List files in subdirectory\n",
    "            sub_artifacts = client.list_artifacts(latest_run_id, artifact.path)\n",
    "            for sub in sub_artifacts:\n",
    "                print(f\"   ‚îî‚îÄ {sub.path}\")\n",
    "else:\n",
    "    print(\"No runs found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b5a2a-d4dd-47a5-834f-4ff778368afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [9]: Instructions for MLflow UI\n",
    "print(\"üöÄ TO VIEW MLFLOW UI:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. Open a NEW terminal/command prompt\")\n",
    "print(\"2. Navigate to project directory:\")\n",
    "print(f\"   cd {os.getcwd()}\")\n",
    "print(\"\\n3. Run:\")\n",
    "print(\"   mlflow ui\")\n",
    "print(\"\\n4. Open browser and go to:\")\n",
    "print(\"   http://localhost:5000\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\n‚ú® In the UI you'll see:\")\n",
    "print(\"  ‚úÖ All experiments and runs\")\n",
    "print(\"  ‚úÖ Metrics visualizations\")\n",
    "print(\"  ‚úÖ Parameter comparisons\")\n",
    "print(\"  ‚úÖ Model registry\")\n",
    "print(\"  ‚úÖ Plots and artifacts\")\n",
    "print(\"\\nüí° Keep training running while viewing the UI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3aaeb-4834-4887-a72b-f72ec6e4ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "runs = mlflow.search_runs(experiment_names=[\"customer_conversion_baseline\"])\n",
    "print(f\"Runs found: {len(runs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151dac9c-d51e-46f4-a03b-6a1bc3790229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
