# ML Framework Configuration
# This config file drives all experiments - change parameters here rather than in code

# Experiment metadata
experiment:
  name: "customer_conversion_baseline"
  description: "Baseline model predicting customer conversion from usage patterns"
  tags: ["baseline", "logistic_regression"]
  run_name: "run_01"  # Auto-generated if null (or specify like "run_001")
  data_version: "v1"  # Track which version of data you're using

  # MLflow configuration
  mlflow_tracking_uri: "./mlruns"

# Data configuration
data:
  # Input data paths (relative to project root)
  customers_path: "data/customers.csv"
  noncustomers_path: "data/noncustomers.csv"
  usage_actions_path: "data/usage_actions.csv"

  # Train/test split
  test_size: 0.2
  random_state: 42
  stratify: true  # Stratify by target variable

  # Feature engineering
  features:
    # Aggregation window for usage features (in days)
    lookback_days: 30
    industry_min_frequency: 5

    # Feature scaling
    scaling:
      method: "standard"  # Options: standard, minmax, robust, none
      exclude_columns: []  # Columns to exclude from scaling

    missing_values:
      strategy: "auto" #setting auto means numeric → median and categorical → mode
      constant_value: -1

# Model configuration
model:
  # Model type: logistic_regression, random_forest, xgboost, lightgbm
  type: "logistic_regression"

  # Model hyperparameters (specific to model type)
  hyperparameters:
    # Logistic Regression
    C: 1.0
    penalty: "l2"
    solver: "lbfgs"
    max_iter: 1000
    class_weight: "balanced"  # Handle class imbalance

    # # Random Forest (example - uncomment to use)
    # n_estimators: 100
    # max_depth: 10
    # min_samples_split: 5
    # class_weight: "balanced"

    # # XGBoost (example - uncomment to use)
    # n_estimators: 100
    # learning_rate: 0.1
    # max_depth: 6
    # scale_pos_weight: 1.0  # For imbalanced data

    # # LightGBM (example - uncomment to use)
    # n_estimators: 100
    # learning_rate: 0.1
    # num_leaves: 31
    # is_unbalance: true

# Training configuration
training:
  # Cross-validation
  cross_validation:
    enabled: true
    n_folds: 5
    stratified: true

  # Early stopping (for tree-based models)
  early_stopping:
    enabled: false
    rounds: 10

  # Evaluation metrics to track
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "roc_auc"
    - "average_precision"

  # Classification threshold (for binary classification)
  threshold: 0.5

# Serving configuration
serving:
  # Output format for predictions
  output_format: "csv"  # Options: csv, json, parquet

  # Include prediction probabilities
  include_probabilities: true

  # Batch size for large-scale inference
  batch_size: 1000

# Artifact management
artifacts:
  # Base directory for all artifacts
  base_dir: "artifacts"

  # Subdirectories
  models_dir: "models"
  metrics_dir: "metrics"
  plots_dir: "plots"
  predictions_dir: "predictions"

  # Save artifacts
  save:
    model: true
    metrics: true
    feature_importance: true
    confusion_matrix: true
    roc_curve: true
    predictions: true

  # Model versioning strategy
  versioning:
    strategy: "timestamp"  # Options: timestamp, sequential, git_hash

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  save_to_file: true
  log_file: "experiment.log"

# Reproducibility
reproducibility:
  seed: 42
  deterministic: true  # Set all random seeds for reproducibility
